{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "#grayscale\n",
    "def grayscale(img):\n",
    "    return cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#blur\n",
    "def gaussian_blur(img,kernel_size):\n",
    "    return cv2.GaussianBlur(img,(kernel_size,kernel_size),0)\n",
    "#canny\n",
    "def canny(img,low_threshold,high_threshold):\n",
    "    return cv2.Canny(img,low_threshold,high_threshold)\n",
    "#관심영역 설정\n",
    "def region_of_interest(img,vertices):\n",
    "    mask=np.zeros_like(img)\n",
    "\n",
    "    if len(img.shape)>2:\n",
    "        channel_count=img.shape[2]\n",
    "        ignore_mask_color=(255,)*channel_count\n",
    "    else:\n",
    "        ignore_mask_color=255\n",
    "\n",
    "    cv2.fillPoly(mask,vertices,ignore_mask_color)\n",
    "    \n",
    "    masked_image=cv2.bitwise_and(img,mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img,lines,color=[255,0,0],thickness=5):\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img,(x1,y1),(x2,y2),color,thickness)\n",
    "\n",
    "def hough_lines(img,rho,theta,threshold,min_line_len,max_line_gap):\n",
    "    lines=cv2.HoughLinesP(img,rho,theta,threshold,np.array([]),minLineLength=min_line_len,maxLineGap=max_line_gap)\n",
    "    line_img=np.zeros((img.shape[0],img.shape[1],3),dtype=np.uint8)\n",
    "    draw_lines(line_img,lines)\n",
    "    return lines\n",
    "\n",
    "def draw_fit_line(img, lines, color=[255, 0, 0], thickness=10): # 대표선 그리기\n",
    "        cv2.line(img, (lines[0], lines[1]), (lines[2], lines[3]), color, thickness)\n",
    "\n",
    "def weighted_img(img,initial_img,a=0.8,b=1.,c=0.):\n",
    "    return cv2.addWeighted(initial_img,a,img,b,c)\n",
    "\n",
    "def get_fitline(img, f_lines): # 대표선 구하기   \n",
    "    lines = np.squeeze(f_lines)\n",
    "    lines = lines.reshape(lines.shape[0]*2,2)\n",
    "    rows,cols = img.shape[:2]\n",
    "    output = cv2.fitLine(lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0]-1)-y)/vy*vx + x) , img.shape[0]-1\n",
    "    x2, y2 = int(((img.shape[0]/2+100)-y)/vy*vx + x) , int(img.shape[0]/2+100)\n",
    "    \n",
    "    result = [x1,y1,x2,y2]\n",
    "    return result\n",
    "\n",
    "kernel_size=3\n",
    "low_threshold=70\n",
    "high_threshold=210\n",
    "\n",
    "rho=1\n",
    "theta=np.pi/180\n",
    "threshold=30\n",
    "min_line_len=10\n",
    "max_line_gap=20\n",
    "\n",
    "#capture = cv2.VideoCapture('challenge.mp4')\n",
    "\n",
    "while True:\n",
    "    img=cv2.imread('slope_test.jpg')\n",
    "    # ret, img = capture.read()\n",
    "\n",
    "    gray=grayscale(img)\n",
    "    blur_gray=gaussian_blur(gray,kernel_size)\n",
    "    edges=canny(blur_gray,low_threshold,high_threshold)\n",
    "    mask=np.zeros_like(img)\n",
    "\n",
    "    if len(img.shape)>2:\n",
    "        channel_count=img.shape[2]\n",
    "        ignore_mask_color=(255,)*channel_count\n",
    "    else:\n",
    "        ignore_mask_color=255\n",
    "\n",
    "    imshape=img.shape\n",
    "    vertices=np.array([[(50,imshape[0]),(imshape[1]*2/5,imshape[0]/2),(imshape[1]*3/5,imshape[0]/2),(imshape[1]-50,imshape[0])]],dtype=np.int32)\n",
    "    # vertices=np.array([[(180,imshape[0]),(600,400),(900,400),(1300,imshape[0])]],dtype=np.int32)\n",
    "    mask=region_of_interest(edges,vertices)\n",
    "\n",
    "\n",
    "    lines=hough_lines(mask,rho,theta,threshold,min_line_len,max_line_gap)\n",
    "    #lines_edges=weighted_img(lines,img,a=0.8,b=1.,c=0.)\n",
    "    lines = np.squeeze(lines)\n",
    "    \n",
    "    # 기울기 구하기\n",
    "    slope_degree = (np.arctan2(lines[:,1] - lines[:,3], lines[:,0] - lines[:,2]) * 180) / np.pi\n",
    "\n",
    "    # 수평 기울기 제한\n",
    "    lines = lines[np.abs(slope_degree)<160]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)<160]\n",
    "    # 수직 기울기 제한\n",
    "    lines = lines[np.abs(slope_degree)>95]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "    # 필터링된 직선 버리기\n",
    "    L_lines, R_lines = lines[(slope_degree>0),:], lines[(slope_degree<0),:]\n",
    "    temp = np.zeros((imshape[0], imshape[1], 3), dtype=np.uint8)\n",
    "    L_lines, R_lines = L_lines[:,None], R_lines[:,None]\n",
    "    # 왼쪽, 오른쪽 각각 대표선 구하기\n",
    "    left_fit_line = get_fitline(img,L_lines)\n",
    "    right_fit_line = get_fitline(img,R_lines)\n",
    "    # 대표선 그리기\n",
    "    draw_fit_line(temp, left_fit_line)\n",
    "    draw_fit_line(temp, right_fit_line)\n",
    "\n",
    "    result = weighted_img(temp, img) # 원본 이미지에 검출된 선 overlap\n",
    "    cv2.imshow('result',result) # 결과 이미지 출력\n",
    "\n",
    "    #cv2.imshow('myimg', lines_edges)\n",
    "\n",
    "    if cv2.waitKey(33) == ord('q'):\n",
    "        break\n",
    "\n",
    "#camera.release()\n",
    "#capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    mask = np.zeros_like(img)\n",
    "    match_mask_color = 255\n",
    "    cv2.fillPoly(mask, vertices, match_mask_color)\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=3):\n",
    "    line_img = np.zeros_like(img)\n",
    "    img = np.copy(img)\n",
    "    if lines is None:\n",
    "        return\n",
    "    left_line_x = []\n",
    "    left_line_y = []\n",
    "    right_line_x = []\n",
    "    right_line_y = []\n",
    "    \n",
    "    for line in lines:\n",
    "        for x1, y1, x2, y2 in line:\n",
    "            slope = (y2 - y1) / (x2 - x1)\n",
    "            if math.fabs(slope) < 0.5:\n",
    "                continue\n",
    "            if slope <= 0:\n",
    "                left_line_x.extend([x1, x2])\n",
    "                left_line_y.extend([y1, y2])\n",
    "            else:\n",
    "                right_line_x.extend([x1, x2])\n",
    "                right_line_y.extend([y1, y2])\n",
    "\n",
    "    try:\n",
    "        if len(left_line_x) > 1 and len(left_line_y) > 1:\n",
    "            left_poly = np.polyfit(left_line_y, left_line_x, deg=2)\n",
    "            left_fit = np.poly1d(left_poly)\n",
    "\n",
    "            for y in range(img.shape[0]//2, img.shape[0]):\n",
    "                x = int(left_fit(y))\n",
    "                if x >= 0:  # Ensure x is non-negative\n",
    "                    cv2.circle(line_img, (x, y), 2, color, thickness)\n",
    "    except Exception as e:\n",
    "        print(\"Left Polyfit Error:\", e)\n",
    "\n",
    "    try:\n",
    "        if len(right_line_x) > 1 and len(right_line_y) > 1:\n",
    "            right_poly = np.polyfit(right_line_y, right_line_x, deg=2)\n",
    "            right_fit = np.poly1d(right_poly)\n",
    "\n",
    "            for y in range(img.shape[0]//2, img.shape[0]):\n",
    "                x = int(right_fit(y))\n",
    "                if x >= 0:  # Ensure x is non-negative\n",
    "                    cv2.circle(line_img, (x, y), 2, color, thickness)\n",
    "    except Exception as e:\n",
    "        print(\"Right Polyfit Error:\", e)\n",
    "\n",
    "    img = cv2.addWeighted(img, 0.8, line_img, 1.0, 0.0)\n",
    "    return img\n",
    "\n",
    "def pipeline(image):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    region_of_interest_vertices = [\n",
    "        (width / 5, height),\n",
    "        (width*0.4, height *0.6),\n",
    "        (width*0.6, height *0.6),\n",
    "        (width, height)\n",
    "    ]\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    cannyed_image = cv2.Canny(gray_image, 50, 150)\n",
    "\n",
    "    cropped_image = region_of_interest(\n",
    "        cannyed_image,\n",
    "        np.array(\n",
    "            [region_of_interest_vertices],\n",
    "            np.int32\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    lines = cv2.HoughLinesP(\n",
    "        cropped_image,\n",
    "        # rho=4,\n",
    "        # theta=np.pi / 60,\n",
    "        # threshold=160,\n",
    "        # lines=np.array([]),\n",
    "        # minLineLength=40,\n",
    "        # maxLineGap=25\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=30,\n",
    "        lines=np.array([]),\n",
    "        minLineLength=10,\n",
    "        maxLineGap=20\n",
    "    )\n",
    "\n",
    "    line_image = draw_lines(image, lines, thickness=5)\n",
    "    return line_image\n",
    "\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "white_output = 'test5_output.mp4'\n",
    "clip1 = VideoFileClip(\"test5.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline)\n",
    "white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python file uses the following encoding: utf-8\n",
    "#-*- coding: cp949 -*-\n",
    "#-*- coding: utf-8 -*- \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import os, sys\n",
    "#%matplotlib inline\n",
    "       \n",
    "#cap = cv2.VideoCapture('solidWhiteRight.mp4')\n",
    "#cap = cv2.VideoCapture('solidYellowLeft.mp4')\n",
    "cap = cv2.VideoCapture('solidWhiteRight.mp4')\n",
    "fit_result, l_fit_result, r_fit_result, L_lane,R_lane = [], [], [], [], []\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'mp4v') # Be sure to use the lower case\n",
    "#out = cv2.VideoWriter('output.mp4', fourcc, 20.0, ( 960, 540 ))\n",
    "\n",
    "def grayscale(img):\n",
    "    \"\"\"Applies the Grayscale transform\n",
    "    This will return an image with only one color channel\n",
    "    but NOTE: to see the returned image as grayscale\n",
    "    you should call plt.imshow(gray, cmap='gray')\"\"\"\n",
    "    return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def canny(img, low_threshold, high_threshold):\n",
    "    \"\"\"Applies the Canny transform\"\"\"\n",
    "    return cv2.Canny(img, low_threshold, high_threshold)\n",
    "\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    \"\"\"\n",
    "    Applies an image mask.\n",
    "    \n",
    "    Only keeps the region of the image defined by the polygon\n",
    "    formed from `vertices`. The rest of the image is set to black.\n",
    "    \"\"\"\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def draw_lines(img, lines, color=[255, 0, 0], thickness=2):\n",
    "    \"\"\"\n",
    "    NOTE: this is the function you might want to use as a starting point once you want to \n",
    "    average/extrapolate the line segments you detect to map out the full\n",
    "    extent of the lane (going from the result shown in raw-lines-example.mp4\n",
    "    to that shown in P1_example.mp4).  \n",
    "    \n",
    "    Think about things like separating line segments by their \n",
    "    slope ((y2-y1)/(x2-x1)) to decide which segments are part of the left\n",
    "    line vs. the right line.  Then, you can average the position of each of \n",
    "    the lines and extrapolate to the top and bottom of the lane.\n",
    "    \n",
    "    This function draws `lines` with `color` and `thickness`.    \n",
    "    Lines are drawn on the image inplace (mutates the image).\n",
    "    If you want to make the lines semi-transparent, think about combining\n",
    "    this function with the weighted_img() function below\n",
    "    \"\"\"\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            cv2.line(img, (x1, y1), (x2, y2), color, thickness)\n",
    "\n",
    "def draw_circle(img,lines, color=[0, 0, 255]):\n",
    "    for line in lines:\n",
    "        cv2.circle(img,(line[0],line[1]), 2, color, -1)\n",
    "\n",
    "def hough_lines(img, rho, theta, threshold, min_line_len, max_line_gap):\n",
    "    \"\"\"\n",
    "    `img` should be the output of a Canny transform.        \n",
    "    Returns an image with hough lines drawn.\n",
    "    \"\"\"\n",
    "    lines = cv2.HoughLinesP(img, rho, theta, threshold, np.array([]), minLineLength=min_line_len, maxLineGap=max_line_gap)\n",
    "    line_arr = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
    "    #draw_lines(line_arr, lines)\n",
    "    return lines\n",
    "\n",
    "def weighted_img(img, initial_img, α=0.8, β=1., λ=0.):\n",
    "    \"\"\"\n",
    "    `img` is the output of the hough_lines(), An image with lines drawn on it.\n",
    "    Should be a blank image (all black) with lines drawn on it.\n",
    "    \n",
    "    `initial_img` should be the image before any processing.\n",
    "    \n",
    "    The result image is computed as follows:\n",
    "    \n",
    "    initial_img * α + img * β + λ\n",
    "    NOTE: initial_img and img must be the same shape!\n",
    "    \"\"\"\n",
    "    return cv2.addWeighted(initial_img, α, img, β, λ)\n",
    "\n",
    "def Collect_points(lines):\n",
    "\n",
    "    # reshape [:4] to [:2]\n",
    "    interp = lines.reshape(lines.shape[0]*2,2)\n",
    "    # interpolation & collecting points for RANSAC\n",
    "    for line in lines:\n",
    "        if np.abs(line[3]-line[1]) > 5:\n",
    "            tmp = np.abs(line[3]-line[1])\n",
    "            a = line[0] ; b = line[1] ; c = line[2] ; d = line[3]\n",
    "            slope = (line[2]-line[0])/(line[3]-line[1]) \n",
    "            for m in range(0,tmp,5):\n",
    "                if slope>0:\n",
    "                    new_point = np.array([[int(a+m*slope),int(b+m)]])\n",
    "                    interp = np.concatenate((interp,new_point),axis = 0)\n",
    "                elif slope<0:\n",
    "                    new_point = np.array([[int(a-m*slope),int(b-m)]])\n",
    "                    interp = np.concatenate((interp,new_point),axis = 0)                \n",
    "    return interp\n",
    "\n",
    "def get_random_samples(lines):\n",
    "    one = random.choice(lines)\n",
    "    two = random.choice(lines)\n",
    "    if(two[0]==one[0]): # extract again if values are overlapped\n",
    "        while two[0]==one[0]:\n",
    "            two = random.choice(lines)\n",
    "    one, two = one.reshape(1,2), two.reshape(1,2)\n",
    "    three = np.concatenate((one,two),axis=1)\n",
    "    three = three.squeeze()\n",
    "    return three\n",
    "\n",
    "def compute_model_parameter(line):\n",
    "    # y = mx+n\n",
    "    m = (line[3] - line[1])/(line[2] - line[0])\n",
    "    n = line[1] - m*line[0]\n",
    "    # ax+by+c = 0\n",
    "    a, b, c = m, -1, n\n",
    "    par = np.array([a,b,c])\n",
    "    return par\n",
    "\n",
    "def compute_distance(par, point):\n",
    "    # distance between line & point\n",
    "    \n",
    "    return np.abs(par[0]*point[:,0]+par[1]*point[:,1]+par[2])/np.sqrt(par[0]**2+par[1]**2)\n",
    "\n",
    "def model_verification(par, lines):\n",
    "    # calculate distance\n",
    "    distance = compute_distance(par,lines)\n",
    "    # total sum of distance between random line and sample points    \n",
    "    sum_dist = distance.sum(axis=0)\n",
    "    # average\n",
    "    avg_dist = sum_dist/len(lines)\n",
    "    \n",
    "    return avg_dist\n",
    "\n",
    "def draw_extrapolate_line(img, par,color=(0,0,255), thickness = 2):\n",
    "\n",
    "    x1, y1 = int(-par[1]/par[0]*img.shape[0]-par[2]/par[0]), int(img.shape[0])\n",
    "    x2, y2 = int(-par[1]/par[0]*(img.shape[0]/2+100)-par[2]/par[0]), int(img.shape[0]/2+100)\n",
    "    cv2.line(img, (x1 , y1), (x2, y2), color, thickness)\n",
    "    return img\n",
    "\n",
    "def get_fitline(img, f_lines):\n",
    "\n",
    "    rows,cols = img.shape[:2]\n",
    "    output = cv2.fitLine(f_lines,cv2.DIST_L2,0, 0.01, 0.01)\n",
    "    vx, vy, x, y = output[0], output[1], output[2], output[3]\n",
    "    x1, y1 = int(((img.shape[0]-1)-y)/vy*vx + x) , img.shape[0]-1\n",
    "    x2, y2 = int(((img.shape[0]/2+100)-y)/vy*vx + x) , int(img.shape[0]/2+100)\n",
    "    result = [x1,y1,x2,y2]\n",
    "\n",
    "    return result\n",
    "\n",
    "def draw_fitline(img, result_l,result_r, color=(255,0,255), thickness = 10):\n",
    "    # draw fitting line\n",
    "    lane = np.zeros_like(img)\n",
    "    cv2.line(lane, (int(result_l[0]) , int(result_l[1])), (int(result_l[2]), int(result_l[3])), color, thickness)\n",
    "    cv2.line(lane, (int(result_r[0]) , int(result_r[1])), (int(result_r[2]), int(result_r[3])), color, thickness)\n",
    "    # add original image & extracted lane lines\n",
    "    final = weighted_img(lane, img, 1,0.5)  \n",
    "    return final\n",
    "\n",
    "def erase_outliers(par, lines):\n",
    "    # distance between best line and sample points\n",
    "    distance = compute_distance(par,lines)\n",
    "\n",
    "    #filtered_dist = distance[distance<15]\n",
    "    filtered_lines = lines[distance<13,:]\n",
    "    return filtered_lines\n",
    "\n",
    "def smoothing(lines, pre_frame):\n",
    "    # collect frames & print average line\n",
    "    lines = np.squeeze(lines)\n",
    "    avg_line = np.array([0,0,0,0])\n",
    "    \n",
    "    for ii,line in enumerate(reversed(lines)):\n",
    "        if ii == pre_frame:\n",
    "            break\n",
    "        avg_line += line\n",
    "    avg_line = avg_line / pre_frame\n",
    "\n",
    "    return avg_line\n",
    "\n",
    "def ransac_line_fitting(img, lines, min=100):\n",
    "    global fit_result, l_fit_result, r_fit_result\n",
    "    best_line = np.array([0,0,0])\n",
    "    if(len(lines)!=0):                \n",
    "        for i in range(30):           \n",
    "            sample = get_random_samples(lines)\n",
    "            parameter = compute_model_parameter(sample)\n",
    "            cost = model_verification(parameter, lines)                        \n",
    "            if cost < min: # update best_line\n",
    "                min = cost\n",
    "                best_line = parameter\n",
    "            if min < 3: break\n",
    "        # erase outliers based on best line\n",
    "        filtered_lines = erase_outliers(best_line, lines)\n",
    "        fit_result = get_fitline(img, filtered_lines)\n",
    "    else:\n",
    "        if (fit_result[3]-fit_result[1])/(fit_result[2]-fit_result[0]) < 0:\n",
    "            l_fit_result = fit_result\n",
    "            return l_fit_result\n",
    "        else:\n",
    "            r_fit_result = fit_result\n",
    "            return r_fit_result\n",
    "\n",
    "    if (fit_result[3]-fit_result[1])/(fit_result[2]-fit_result[0]) < 0:\n",
    "        l_fit_result = fit_result\n",
    "        return l_fit_result\n",
    "    else:\n",
    "        r_fit_result = fit_result\n",
    "        return r_fit_result\n",
    "\n",
    "def detect_lanes_img(img):\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Set ROI\n",
    "    vertices = np.array([[(50,height),(width/2-45, height/2+60), (width/2+45, height/2+60), (width-50,height)]], dtype=np.int32)\n",
    "    ROI_img = region_of_interest(img, vertices)\n",
    "    \n",
    "    # Convert to grayimage\n",
    "    #g_img = grayscale(img)\n",
    "       \n",
    "    # Apply gaussian filter\n",
    "    blur_img = gaussian_blur(ROI_img, 3)\n",
    "        \n",
    "    # Apply Canny edge transform\n",
    "    canny_img = canny(blur_img, 70, 210)\n",
    "    # to except contours of ROI image\n",
    "    vertices2 = np.array([[(52,height),(width/2-43, height/2+62), (width/2+43, height/2+62), (width-52,height)]], dtype=np.int32)\n",
    "    canny_img = region_of_interest(canny_img, vertices2)\n",
    "\n",
    "    # Perform hough transform\n",
    "    # Get first candidates for real lane lines  \n",
    "    line_arr = hough_lines(canny_img, 1, 1 * np.pi/180, 30, 10, 20)\n",
    "    \n",
    "    #draw_lines(img, line_arr, thickness=2)\n",
    "\n",
    "    line_arr = np.squeeze(line_arr)\n",
    "    # Get slope degree to separate 2 group (+ slope , - slope)\n",
    "    slope_degree = (np.arctan2(line_arr[:,1] - line_arr[:,3], line_arr[:,0] - line_arr[:,2]) * 180) / np.pi\n",
    "\n",
    "    # ignore horizontal slope lines\n",
    "    line_arr = line_arr[np.abs(slope_degree)<160]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)<160]\n",
    "    # ignore vertical slope lines\n",
    "    line_arr = line_arr[np.abs(slope_degree)>95]\n",
    "    slope_degree = slope_degree[np.abs(slope_degree)>95]\n",
    "    L_lines, R_lines = line_arr[(slope_degree>0),:], line_arr[(slope_degree<0),:]\n",
    "    #print(line_arr.shape,'  ',L_lines.shape,'  ',R_lines.shape)\n",
    "    \n",
    "    # interpolation & collecting points for RANSAC\n",
    "    L_interp = Collect_points(L_lines)\n",
    "    R_interp = Collect_points(R_lines)\n",
    "\n",
    "    #draw_circle(img,L_interp,(255,255,0))\n",
    "    #draw_circle(img,R_interp,(0,255,255))\n",
    "\n",
    "    # erase outliers based on best line\n",
    "    left_fit_line = ransac_line_fitting(img, L_interp)\n",
    "    right_fit_line = ransac_line_fitting(img, R_interp)\n",
    "\n",
    "    # smoothing by using previous frames\n",
    "    L_lane.append(left_fit_line), R_lane.append(right_fit_line)\n",
    "\n",
    "    if len(L_lane) > 10:\n",
    "        left_fit_line = smoothing(L_lane, 10)    \n",
    "    if len(R_lane) > 10:\n",
    "        right_fit_line = smoothing(R_lane, 10)\n",
    "    final = draw_fitline(img, left_fit_line, right_fit_line)\n",
    "\n",
    "    return final\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if frame is None:\n",
    "        # 프레임이 더 이상 없으면 루프를 종료합니다.\n",
    "        break\n",
    "\n",
    "    # if frame.shape[0] != 540:  # 도전 동영상을 위한 크기 조정\n",
    "    #     frame = cv2.resize(frame, None, fx=3/4, fy=3/4, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    result = detect_lanes_img(frame)\n",
    "\n",
    "    cv2.imshow('result', result)\n",
    "\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "0.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
