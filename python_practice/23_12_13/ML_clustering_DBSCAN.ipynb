{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate synthetic data (moon-shaped clusters)\n",
    "X, _ = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "X = StandardScaler().fit_transform(X)\n",
    "\n",
    "# Apply DBSCAN\n",
    "epsilon = 0.3\n",
    "min_samples = 5\n",
    "dbscan = DBSCAN(eps=epsilon, min_samples=min_samples)\n",
    "cluster_labels = dbscan.fit_predict(X)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis', s=50, edgecolors='k')\n",
    "plt.title('DBSCAN Clustering with scikit-learn')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return torch.sqrt(torch.sum((x1 - x2)**2))\n",
    "\n",
    "def range_query(data, point_index, epsilon):\n",
    "    neighbors = []\n",
    "    for i in range(len(data)):\n",
    "        if euclidean_distance(data[point_index], data[i]) < epsilon:\n",
    "            neighbors.append(i)\n",
    "    return torch.tensor(neighbors, dtype=torch.long)\n",
    "\n",
    "def expand_cluster(data, labels, point_index, neighbors, cluster_id, epsilon, min_samples):\n",
    "    labels[point_index] = cluster_id\n",
    "    i = 0\n",
    "    while i < len(neighbors):\n",
    "        neighbor = neighbors[i]\n",
    "        if labels[neighbor] == -1:\n",
    "            labels[neighbor] = cluster_id\n",
    "        elif labels[neighbor] == 0:\n",
    "            labels[neighbor] = cluster_id\n",
    "            new_neighbors = range_query(data, neighbor, epsilon)\n",
    "            if len(new_neighbors) >= min_samples:\n",
    "                neighbors = torch.cat((neighbors, new_neighbors))\n",
    "        i += 1\n",
    "\n",
    "def dbscan(data, epsilon, min_samples):\n",
    "    labels = torch.zeros(len(data), dtype=torch.long)\n",
    "    cluster_id = 1\n",
    "    for i in range(len(data)):\n",
    "        if labels[i] != 0:\n",
    "            continue\n",
    "        neighbors = range_query(data, i, epsilon)\n",
    "        if len(neighbors) < min_samples:\n",
    "            labels[i] = -1\n",
    "        else:\n",
    "            expand_cluster(data, labels, i, neighbors, cluster_id, epsilon, min_samples)\n",
    "            cluster_id += 1\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Example usage with make_moons data:\n",
    "X, _ = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "data = torch.tensor(X, dtype=torch.float32)\n",
    "# data = torch.rand((100, 2))\n",
    "\n",
    "epsilon = 0.3\n",
    "min_samples = 5\n",
    "\n",
    "cluster_labels = dbscan(data, epsilon, min_samples)\n",
    "# print(\"cluster_labels\", cluster_labels)\n",
    "\n",
    "# Visualization\n",
    "plt.scatter(data[:, 0], data[:, 1], c=cluster_labels.numpy(), cmap='viridis', s=50, edgecolors='k')\n",
    "plt.title('DBSCAN Clustering with make_moons data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
